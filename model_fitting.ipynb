{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **High Frequency Trading Strategies Design using ML and DL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sun Mar 13 22:40:00 2022\\n\\n@author: Bradley\\n\\nHFT: Machine Learning Techniques on Full Orderbook Tick Data\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Mar 13 22:40:00 2022\n",
    "\n",
    "@author: Bradley\n",
    "\n",
    "HFT: Machine Learning Techniques on Full Orderbook Tick Data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (8,5) #提前设置图片形状大小\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略一些warnings\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features\n",
    "def read_csv(day_trade):\n",
    "    data_up = []\n",
    "    data_down = []\n",
    "    for j,i in enumerate(day_trade):\n",
    "        for k in range(0,len(i),1):\n",
    "            path_up = './processed_data/order_book_3_2014_new' + '_' + str(j+1) + '_' + str(i[k]) + '_' + 'UP' + '.csv'\n",
    "            path_down = './processed_data/order_book_3_2014_new' + '_' + str(j+1) + '_' + str(i[k]) + '_' + 'DOWN' + '.csv'\n",
    "            data_up.append(pd.read_csv(path_up))\n",
    "            data_down.append(pd.read_csv(path_down))\n",
    "    return data_up,data_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# 如果有更多的天数，只用改变日期参数即可\n",
    "day_trade = [[2]]\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553936</td>\n",
       "      <td>4.656716</td>\n",
       "      <td>0.646438</td>\n",
       "      <td>1.532051</td>\n",
       "      <td>0.210127</td>\n",
       "      <td>2.462585</td>\n",
       "      <td>0.422397</td>\n",
       "      <td>14.074595</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>7100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553936</td>\n",
       "      <td>4.656716</td>\n",
       "      <td>0.646438</td>\n",
       "      <td>1.532051</td>\n",
       "      <td>0.210127</td>\n",
       "      <td>2.462585</td>\n",
       "      <td>0.422397</td>\n",
       "      <td>14.074595</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>7100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497382</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>-0.476190</td>\n",
       "      <td>2.396396</td>\n",
       "      <td>0.411141</td>\n",
       "      <td>1.803571</td>\n",
       "      <td>0.286624</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497382</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>-0.476190</td>\n",
       "      <td>1.003774</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>-0.047170</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926773</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>-0.921986</td>\n",
       "      <td>0.406107</td>\n",
       "      <td>-0.422367</td>\n",
       "      <td>0.268617</td>\n",
       "      <td>-0.576520</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926773</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>-0.921986</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>-0.411638</td>\n",
       "      <td>0.275266</td>\n",
       "      <td>-0.568300</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926773</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>-0.921986</td>\n",
       "      <td>0.737405</td>\n",
       "      <td>-0.151142</td>\n",
       "      <td>0.474734</td>\n",
       "      <td>-0.356177</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>-0.915194</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>-0.150132</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>-0.353735</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>-0.915194</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>-0.150132</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>-0.353735</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.912188</td>\n",
       "      <td>0.049815</td>\n",
       "      <td>-0.905097</td>\n",
       "      <td>0.741985</td>\n",
       "      <td>-0.148116</td>\n",
       "      <td>0.481383</td>\n",
       "      <td>-0.350090</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1        2        3        4        5        6        7        8        9  ...        58        59        60        61        62        63        64         65      66      67\n",
       "0  0.0  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  ...  0.553936  4.656716  0.646438  1.532051  0.210127  2.462585  0.422397  14.074595  7110.0  7100.0\n",
       "1  0.0  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  ...  0.553936  4.656716  0.646438  1.532051  0.210127  2.462585  0.422397  14.074595  7110.0  7100.0\n",
       "2  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.497382  0.354839 -0.476190  2.396396  0.411141  1.803571  0.286624  14.044944  7125.0  7115.0\n",
       "3  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.497382  0.354839 -0.476190  1.003774  0.001883  0.909910 -0.047170  14.044944  7125.0  7115.0\n",
       "4  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.926773  0.040590 -0.921986  0.406107 -0.422367  0.268617 -0.576520  14.044944  7125.0  7115.0\n",
       "5  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.926773  0.040590 -0.921986  0.416794 -0.411638  0.275266 -0.568300  14.044944  7125.0  7115.0\n",
       "6  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.926773  0.040590 -0.921986  0.737405 -0.151142  0.474734 -0.356177  14.044944  7125.0  7115.0\n",
       "7  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.922374  0.044280 -0.915194  0.738931 -0.150132  0.477394 -0.353735  14.044944  7125.0  7115.0\n",
       "8  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.922374  0.044280 -0.915194  0.738931 -0.150132  0.477394 -0.353735  14.044944  7125.0  7115.0\n",
       "9  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.912188  0.049815 -0.905097  0.741985 -0.148116  0.481383 -0.350090  14.044944  7125.0  7115.0\n",
       "\n",
       "[10 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0列是要预测的label\n",
    "\n",
    "# 查看上午的feature数据，第一列为0代表not trade，第一列为1代表trade，后面列都是feature value\n",
    "data_2014_up[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置需要使用到的ML、DL模型，设置random_state使结果可复制\n",
    "# 可以自行添加更多的分类器，例如MLP，xgboost，软投票分类器等等二分类工具\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state = 0),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 0),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 10,random_state = 0),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 0),\n",
    "    'SVC': SVC(probability=True,random_state = 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置hyperparameter tuning的网格搜索参数\n",
    "\n",
    "model_grid_params = {\n",
    "    'RandomForestClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                               'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                               'min_samples_leaf':[3]},\n",
    "    'ExtraTreesClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                             'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                             'min_samples_leaf':[3]},\n",
    "    'AdaBoostClassifier': {\"base_estimator__criterion\" : [\"entropy\"],\\\n",
    "                           \"base_estimator__max_depth\": [None],\\\n",
    "                           \"base_estimator__min_samples_leaf\" : [3],\\\n",
    "                           \"base_estimator__min_samples_split\" : [2],\\\n",
    "                           \"base_estimator__max_features\" : [None]},\n",
    "    'GradientBoostingClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                                   'min_samples_split':[2],'min_samples_leaf':[3],\\\n",
    "                                   'learning_rate':[0.1],'subsample':[1.0]},\n",
    "    'SVC': [{'kernel':['rbf'],'gamma':[1e-1],'C':[1]},\\\n",
    "            {'kernel':['linear'],'C':[1, 10]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Selection Pipline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Selection:\n",
    "    \n",
    "    def __init__(self,models,model_grid_params,data_2014,latest_sec,pred_sec,day):\n",
    "        self.models = models\n",
    "        self.model_grid = model_grid_params\n",
    "        self.data_2014 = data_2014\n",
    "        self.latest_sec = latest_sec\n",
    "        self.pred_sec = pred_sec\n",
    "        self.day = day\n",
    "        self.keys = models.keys()\n",
    "        self.best_score = {}\n",
    "        self.grid = {}\n",
    "        self.predict_values = {}\n",
    "        self.cv_acc = {}\n",
    "        self.acc = {}\n",
    "        self.fscore = {}\n",
    "        self.true_values = {}\n",
    "        self.predict_values_day = {}\n",
    "        self.cv_acc_day = {}\n",
    "        self.acc_day = {}\n",
    "        self.fscore_day = {}\n",
    "        self.true_values_day = {}\n",
    "        self.summary_day = []\n",
    "        \n",
    "    def Grid_fit(self,X_train,y_train,cv = 5,scoring = 'accuracy'):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            model_grid = self.model_grid[key]\n",
    "            Grid = GridSearchCV(model, model_grid, cv = cv, scoring = scoring)\n",
    "            Grid.fit(X_train,y_train) \n",
    "            self.grid[key] = Grid\n",
    "            print(Grid.best_params_)\n",
    "            print('CV Best Score = %s'%(Grid.best_score_))\n",
    "            self.cv_acc[key].append(Grid.best_score_)  \n",
    "    \n",
    "    def model_fit(self,X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            print(\"Running training & testing for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            # print(self.grid[key].best_params_)\n",
    "            model.set_params(**self.grid[key].best_params_)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            #print 'Prediction latest 15 second = %s'%(predictions)\n",
    "            self.predict_values[key].append(predictions.tolist())\n",
    "            self.true_values[key].append(y_test.tolist())\n",
    "            acc = metrics.accuracy_score(y_test,predictions)\n",
    "            f_score = metrics.f1_score(y_test,predictions)\n",
    "            print('Accuracy = %s'%(acc))\n",
    "            self.acc[key].append(acc)\n",
    "            self.fscore[key].append(f_score)\n",
    "            \n",
    "            if key == 'SVC':\n",
    "                if self.grid[key].best_params_['kernel'] == 'linear':\n",
    "                    feature_imp = dict(zip([i for i in range(0,64,1)],model.coef_[0]))\n",
    "                    Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                    print('Kernel is linear and top five importance features = %s'%(Top_five))\n",
    "                else:\n",
    "                    print('Kernel is rbf')\n",
    "                    pass\n",
    "            else: \n",
    "                feature_imp = dict(zip([i for i in range(0,64,1)],model.feature_importances_))\n",
    "                Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                print('Top five importance features = %s'%(Top_five))\n",
    "                pass\n",
    "\n",
    "    def pipline(self):\n",
    "        \n",
    "        self.set_list_day() # store day values\n",
    "        for day in range(0,self.day,1):\n",
    "            self.set_list() # store values\n",
    "            print('Day = %s'%(day+1))\n",
    "            for i in range(0, 9000-self.latest_sec-600, self.pred_sec):\n",
    "            # for i in range(0, 9000-self.latest_sec-600, self.pred_sec):\n",
    "            # for i in range(0, 200, self.pred_sec):\n",
    "\n",
    "                \n",
    "                print('--------------------Rolling Window Time = %s--------------------'%(i/pred_sec))\n",
    "                # Train data\n",
    "                data_train = self.data_2014[day][i:i+self.latest_sec]\n",
    "                # X_train = data_train.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                X_train = data_train.drop(['0','65','66','67'],axis=1)\n",
    "                y_train = data_train['0']\n",
    "\n",
    "                # Test data\n",
    "                data_test = self.data_2014[day][i + self.latest_sec:i + self.latest_sec + self.pred_sec]\n",
    "                # X_test = data_test.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                X_test = data_test.drop(['0','65','66','67'],axis=1)\n",
    "                y_test = data_test['0']\n",
    "                \n",
    "                #start = time.time()\n",
    "                self.Grid_fit(X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "                self.model_fit(X_train, y_train,X_test,y_test)\n",
    "                #end = time.time()\n",
    "                #print 'Total Time = %s'%(end - start)\n",
    "                \n",
    "            for key in self.keys:\n",
    "                \n",
    "                self.cv_acc_day[key].append(self.cv_acc[key])\n",
    "                self.acc_day[key].append(self.acc[key])\n",
    "                self.fscore_day[key].append(self.fscore[key])\n",
    "                self.true_values_day[key].append(self.true_values[key])\n",
    "                self.predict_values_day[key].append(self.predict_values[key])\n",
    "            \n",
    "            self.summary_day.append(self.score_summary(sort_by = 'Accuracy_mean'))\n",
    "    \n",
    "    def set_list(self):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            self.predict_values[key] = []\n",
    "            self.cv_acc[key] = []\n",
    "            self.acc[key] = []\n",
    "            self.fscore[key] = []\n",
    "            self.true_values[key] = []\n",
    "            \n",
    "    def set_list_day(self):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            self.predict_values_day[key] = []\n",
    "            self.cv_acc_day[key] = []\n",
    "            self.acc_day[key] = []\n",
    "            self.fscore_day[key] = []\n",
    "            self.true_values_day[key] = []\n",
    "            \n",
    "    def score_summary(self,sort_by):\n",
    "        \n",
    "        summary = pd.concat([pd.DataFrame(self.acc.keys()),pd.DataFrame(map(lambda x: np.mean(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.std(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.max(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.min(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.mean(self.fscore[x]), self.fscore))],axis=1)\n",
    "        summary.columns = ['Estimator','Accuracy_mean','Accuracy_std','Accuracy_max','Accuracy_min','F_score']\n",
    "        summary.index.rename('Ranking', inplace=True)\n",
    "        return summary.sort_values(by = [sort_by], ascending=False)\n",
    "          \n",
    "    def print_(self):\n",
    "        print(self.predict_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 试运行一组参数\n",
    "# 此处训练集为30min滚动窗口，测试集为未来10s的label值\n",
    "latest_sec = 60 * 30\n",
    "pred_sec = 10\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)\n",
    "day = 1\n",
    "data_2014 = data_2014_up\n",
    "# day=2\n",
    "# data_2014 = data_2014_up + data_2014_down\n",
    "pip = Model_Selection(models,model_grid_params,data_2014,latest_sec,pred_sec,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day = 1\n",
      "--------------------Rolling Window Time = 0.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n"
     ]
    }
   ],
   "source": [
    "# 模型拟合\n",
    "start = time.time()\n",
    "pip.pipline()\n",
    "end = time.time()\n",
    "print('Total Time = %s'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Performance Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.summary_day[0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.summary_day[1]#.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.summary_day[2]#.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Bid and Best Ask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first day\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (14,5))\n",
    "color_ = ['r','b']\n",
    "plt.plot(data_2014[0]['66'],label = 'Best Ask',color = color_[1])\n",
    "plt.plot(data_2014[0]['67'],label = 'Best Bid',color = color_[0])\n",
    "plt.xlim(0, 9000)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time(s)',size = 15)\n",
    "plt.ylabel('Price',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/best_bid_ask.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Day Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "color = []\n",
    "for key in pip.keys:\n",
    "    plt.plot(np.array(pip.acc_day[key])[0],'-o',label = key,lw = 1,markersize = 3)\n",
    "    plt.legend(loc=0)\n",
    "plt.ylim(-0.5,1.5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('Accuracy',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/single_day_accuracy.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "color_ = ['r','orange','y','g','b']\n",
    "for index,key in enumerate(pip.keys):\n",
    "    plt.plot(np.array(pip.cv_acc_day[key])[0],'-o',label = key,color = color_[index],lw = 1,markersize = 3)\n",
    "#plot(best_cv_score,'-v',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 6)\n",
    "plt.legend(loc = 0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.savefig(\"./images/CV_result.png\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain PnL and Best Cross-Validation Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cum_profit and Best_cv_score\n",
    "dict_ = {}\n",
    "dict_['cum_profit'] = []\n",
    "dict_['Best_cv_score'] = []\n",
    "\n",
    "for day in range(0,1,1):\n",
    "    cum_profit_label = []\n",
    "    cum_profit = []\n",
    "    best_cv_score = []\n",
    "    hold_price = []\n",
    "    true_label = []\n",
    "    predict_label = []\n",
    "    # spread = 0.2 * data_2014[day]['65'][1800:][9::10].values\n",
    "    spread = data_2014[day]['65'][1800:][9::10].values\n",
    "    # loss = 0.2*(data_2014[0]['67'][1800:9000-600][9::10].values - data_2014[day]['67'][1800+600:9000][9::10].values)\n",
    "    # loss = data_2014[0]['67'][1800:9000-600][9::10].values - data_2014[day]['67'][1800+600:9000][9::10].values\n",
    "    loss = -data_2014[day]['65'][1800:][9::10].values\n",
    "    # for j in range(0,len(pip.cv_acc_day.values()[0][day]),1):\n",
    "    for j in range(0,len(pip.cv_acc_day['RandomForestClassifier'][day]),1):\n",
    "    \n",
    "        max_al = {}\n",
    "        for i in range(0,len(pip.keys),1):\n",
    "            max_al[list(pip.keys)[i]] = np.array(pip.cv_acc_day[list(pip.keys)[i]])[day][j]\n",
    "        # select best algorithm in cv = 5    \n",
    "        top_cv_acc = sorted(max_al.items(),key = lambda x : x[1], reverse = True)[0:1][0]\n",
    "        best_cv_score.append(top_cv_acc[1])\n",
    "        submission = pip.predict_values_day[top_cv_acc[0]][day][j][-1]\n",
    "        true_value = pip.true_values_day[top_cv_acc[0]][day][j][-1]\n",
    "        true_label.append(true_value)\n",
    "        predict_label.append(submission)\n",
    "        hold_price.append(data_2014[0]['67'][1800:9000][9::10].values[j])\n",
    "\n",
    "        if submission == true_value:\n",
    "            if submission == 1:\n",
    "                cum_profit_label.append(1)\n",
    "                cum_profit.append(spread[j])\n",
    "            elif submission == 0:\n",
    "                cum_profit_label.append(0)\n",
    "                cum_profit.append(0)\n",
    "        elif submission != true_value:\n",
    "            if submission == 1:\n",
    "                cum_profit_label.append(-1)\n",
    "                cum_profit.append(loss[j])\n",
    "            elif submission == 0:\n",
    "                cum_profit_label.append(0)\n",
    "                cum_profit.append(0)\n",
    "                \n",
    "    dict_['cum_profit'].append(cum_profit)\n",
    "    dict_['Best_cv_score'].append(best_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best CV Score Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = dict_['Best_cv_score']\n",
    "\n",
    "# 取一部分可视化\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(best_cv_score[0][0:250],'-o',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.ylim(0.55,1)\n",
    "plt.savefig(\"./images/best_CV_result.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = dict_['Best_cv_score']\n",
    "\n",
    "# 取全部rolling window可视化\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(best_cv_score[0],'-o',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.savefig(\"./images/best_CV_result_all.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PnL Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_profit = dict_['cum_profit']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(211)\n",
    "plt.plot(cum_profit[0],'-o',label = 'Profit & Loss (bps)',lw = 1,markersize = 3)\n",
    "plt.ylabel('Tick',size = 15)\n",
    "plt.legend(loc=0)\n",
    "# plt.ylim(-7.5,2.5)\n",
    "plt.subplot(212)\n",
    "plt.plot(np.cumsum(cum_profit[0]),'-o',label = 'Cum Profit (bps)',lw = 1,markersize = 2)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('Profit',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/best_CV_result_all.png\", dpi=800)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total profit in bps\n",
    "cum_profit = dict_['cum_profit']\n",
    "prof = [0] + cum_profit[0]\n",
    "pd.DataFrame(np.cumsum(prof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_price[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"signal\": predict_label, \"close\": hold_price})\n",
    "result['pre_close'] = result['close'].shift()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由交易信号产生实际持仓\n",
    "def position_at_close(df):\n",
    "    \"\"\"\n",
    "    根据signal产生实际持仓。考虑涨跌停不能买入卖出的情况。\n",
    "    所有的交易都是发生在产生信号的K线的结束时\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ===由signal计算出实际的每天持有仓位\n",
    "    # 在产生signal的k线结束的时候，进行买入\n",
    "    df['signal'].fillna(method='ffill', inplace=True)\n",
    "    df['signal'].fillna(value=0, inplace=True)  # 将初始行数的signal补全为0\n",
    "    df['pos'] = df['signal'].shift()\n",
    "    df['pos'].fillna(value=0, inplace=True)  # 将初始行数的pos补全为0\n",
    "\n",
    "    return df\n",
    "\n",
    "# 计算资金曲线\n",
    "def equity_curve_with_long_at_close(df, c_rate=2.5/10000, t_rate=1.0/1000, slippage=0.01):\n",
    "    \"\"\"\n",
    "    计算股票的资金曲线。只能做多，不能做空。并且只针对满仓操作\n",
    "    每次交易是以当根K线的收盘价为准。\n",
    "    :param df:\n",
    "    :param c_rate: 手续费，commission fees，默认为万分之2.5\n",
    "    :param t_rate: 印花税，tax，默认为千分之1。etf没有\n",
    "    :param slippage: 滑点，股票默认为0.01元，etf为0.001元\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # ==找出开仓、平仓条件\n",
    "    condition1 = df['pos'] != 0\n",
    "    condition2 = df['pos'] != df['pos'].shift(1)\n",
    "    open_pos_condition = condition1 & condition2\n",
    "\n",
    "    condition1 = df['pos'] != 0\n",
    "    condition2 = df['pos'] != df['pos'].shift(-1)\n",
    "    close_pos_condition = condition1 & condition2\n",
    "\n",
    "\n",
    "    # ===基本参数\n",
    "    initial_cash = 10000  # 初始资金，默认为10000元\n",
    "\n",
    "    # ===在买入的K线\n",
    "    # 在发出信号的当根K线以收盘价买入\n",
    "    df.loc[open_pos_condition, 'stock_num'] = initial_cash * (1 - c_rate) / (df['pre_close'] + slippage)\n",
    "\n",
    "    # 买入股票之后剩余的钱，扣除了手续费\n",
    "    df['cash'] = initial_cash - df['stock_num'] * (df['pre_close'] + slippage) * (1 + c_rate)\n",
    "\n",
    "    # 收盘时的股票净值\n",
    "    df['stock_value'] = df['stock_num'] * df['close']\n",
    "\n",
    "    # ===在买入之后的K线\n",
    "    # 买入之后现金不再发生变动\n",
    "    df['cash'].fillna(method='ffill', inplace=True)\n",
    "    df.loc[df['pos'] == 0, ['cash']] = None\n",
    "\n",
    "    # ===在卖出的K线\n",
    "    # 股票数量变动\n",
    "    df.loc[close_pos_condition, 'stock_num'] = df['stock_value'] / df['close']  # 看2006年初\n",
    "\n",
    "    # 现金变动\n",
    "    df.loc[close_pos_condition, 'cash'] += df.loc[close_pos_condition, 'stock_num'] * (df['close'] - slippage) * (\n",
    "                1 - c_rate - t_rate)\n",
    "    # 股票价值变动\n",
    "    df.loc[close_pos_condition, 'stock_value'] = 0\n",
    "\n",
    "    # ===账户净值\n",
    "    df['net_value'] = df['stock_value'] + df['cash']\n",
    "\n",
    "    # ===计算资金曲线\n",
    "    df['equity_change'] = df['net_value'].pct_change(fill_method=None)\n",
    "    df.loc[open_pos_condition, 'equity_change'] = df.loc[open_pos_condition, 'net_value'] / initial_cash - 1  # 开仓日的收益率\n",
    "    df['equity_change'].fillna(value=0, inplace=True)\n",
    "    df['equity_curve'] = (1 + df['equity_change']).cumprod()\n",
    "    df['equity_curve_base'] = (df['close'] / df['pre_close']).cumprod()\n",
    "\n",
    "    # ===删除无关数据\n",
    "    df.drop(['stock_num', 'cash', 'stock_value', 'net_value'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = position_at_close(result)\n",
    "df = equity_curve_with_long_at_close(result1, 0, 0, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要具体的index，哪里发生了最大回撤，那两行，再加上一些robust处理\n",
    "def max_drawdown(X):\n",
    "    X = np.array(X)\n",
    "    try:\n",
    "        i = np.argmin((X - np.maximum.accumulate(X))/np.maximum.accumulate(X))\n",
    "        j = np.argmax(X[:i])\n",
    "        return i, j, (X[i]-X[j])/X[j]\n",
    "    except:\n",
    "        return 0\n",
    "max_drawdown(df['equity_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算累积收益, exp_rate为业绩报酬率\n",
    "def cum_return(X: pd.Series, exp_rate=0):\n",
    "    X = np.array(X)\n",
    "    t = (X[-1]-X[0])/X[0]\n",
    "    if t > 0:\n",
    "        return t * (1-exp_rate)\n",
    "    else:\n",
    "        return t\n",
    "cum_return(df['equity_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More: Develop the effect of training window period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sec = 10\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)\n",
    "day = 1\n",
    "data_2014 = data_2014_up\n",
    "# day=2\n",
    "# data_2014 = data_2014_up+ data_2014_down\n",
    "\n",
    "color_ = ['r','orange','y','g','b']\n",
    "\n",
    "x = []\n",
    "y = {'RandomForestClassifier': [],\n",
    " 'ExtraTreesClassifier': [],\n",
    " 'AdaBoostClassifier': [],\n",
    " 'GradientBoostingClassifier': [],\n",
    " 'SVC': []}\n",
    "\n",
    "for latest_sec in range(10, 660,2):\n",
    "    pip = Model_Selection(models,model_grid_params,data_2014,latest_sec,pred_sec,day)\n",
    "    pip.pipline()\n",
    "    x.append(latest_sec)\n",
    "    for index,key in enumerate(pip.keys):\n",
    "        y[key].append(pip.cv_acc_day[key][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.ylim(0.6, 1)\n",
    "plt.xlim(0, 700)\n",
    "for index,key in enumerate(pip.keys):\n",
    "    plt.plot(x, y[key],'-o',label = key ,color = color_[index], lw = 1, markersize = 2)\n",
    "    # plot(best_cv_score,'-v',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 6)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Training Sliding Window',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
