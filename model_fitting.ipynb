{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **High Frequency Trading Strategies Design using ML and DL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nCreated on Sun Mar 13 22:40:00 2022\\n\\n@author: Bradley\\n\\nHFT: Machine Learning Techniques on Full Orderbook Tick Data\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Mar 13 22:40:00 2022\n",
    "\n",
    "@author: Bradley\n",
    "\n",
    "HFT: Machine Learning Techniques on Full Orderbook Tick Data\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from datetime import datetime\n",
    "import csv\n",
    "\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "plt.rcParams['figure.figsize'] = (8,5) #提前设置图片形状大小\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # 忽略一些warnings\n",
    "\n",
    "# from IPython.core.interactiveshell import InteractiveShell\n",
    "# InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from IPython.display import display\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "pd.set_option('display.unicode.ambiguous_as_wide', True)\n",
    "pd.set_option('display.unicode.east_asian_width', True)\n",
    "pd.set_option('display.width', 180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import (RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Fitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the features\n",
    "def read_csv(day_trade):\n",
    "    data_up = []\n",
    "    data_down = []\n",
    "    for j,i in enumerate(day_trade):\n",
    "        for k in range(0,len(i),1):\n",
    "            path_up = './processed_data/order_book_3_2014_new' + '_' + str(j+1) + '_' + str(i[k]) + '_' + 'UP' + '.csv'\n",
    "            path_down = './processed_data/order_book_3_2014_new' + '_' + str(j+1) + '_' + str(i[k]) + '_' + 'DOWN' + '.csv'\n",
    "            data_up.append(pd.read_csv(path_up))\n",
    "            data_down.append(pd.read_csv(path_down))\n",
    "    return data_up,data_down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 读取数据\n",
    "# 如果有更多的天数，只用改变日期参数即可\n",
    "day_trade = [[2]]\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553936</td>\n",
       "      <td>4.656716</td>\n",
       "      <td>0.646438</td>\n",
       "      <td>1.532051</td>\n",
       "      <td>0.210127</td>\n",
       "      <td>2.462585</td>\n",
       "      <td>0.422397</td>\n",
       "      <td>14.074595</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>7100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.553936</td>\n",
       "      <td>4.656716</td>\n",
       "      <td>0.646438</td>\n",
       "      <td>1.532051</td>\n",
       "      <td>0.210127</td>\n",
       "      <td>2.462585</td>\n",
       "      <td>0.422397</td>\n",
       "      <td>14.074595</td>\n",
       "      <td>7110.0</td>\n",
       "      <td>7100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497382</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>-0.476190</td>\n",
       "      <td>2.396396</td>\n",
       "      <td>0.411141</td>\n",
       "      <td>1.803571</td>\n",
       "      <td>0.286624</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.497382</td>\n",
       "      <td>0.354839</td>\n",
       "      <td>-0.476190</td>\n",
       "      <td>1.003774</td>\n",
       "      <td>0.001883</td>\n",
       "      <td>0.909910</td>\n",
       "      <td>-0.047170</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926773</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>-0.921986</td>\n",
       "      <td>0.406107</td>\n",
       "      <td>-0.422367</td>\n",
       "      <td>0.268617</td>\n",
       "      <td>-0.576520</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926773</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>-0.921986</td>\n",
       "      <td>0.416794</td>\n",
       "      <td>-0.411638</td>\n",
       "      <td>0.275266</td>\n",
       "      <td>-0.568300</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.926773</td>\n",
       "      <td>0.040590</td>\n",
       "      <td>-0.921986</td>\n",
       "      <td>0.737405</td>\n",
       "      <td>-0.151142</td>\n",
       "      <td>0.474734</td>\n",
       "      <td>-0.356177</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>-0.915194</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>-0.150132</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>-0.353735</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.922374</td>\n",
       "      <td>0.044280</td>\n",
       "      <td>-0.915194</td>\n",
       "      <td>0.738931</td>\n",
       "      <td>-0.150132</td>\n",
       "      <td>0.477394</td>\n",
       "      <td>-0.353735</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>0.21097</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.912188</td>\n",
       "      <td>0.049815</td>\n",
       "      <td>-0.905097</td>\n",
       "      <td>0.741985</td>\n",
       "      <td>-0.148116</td>\n",
       "      <td>0.481383</td>\n",
       "      <td>-0.350090</td>\n",
       "      <td>14.044944</td>\n",
       "      <td>7125.0</td>\n",
       "      <td>7115.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 68 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1        2        3        4        5        6        7        8        9  ...        58        59        60        61        62        63        64         65      66      67\n",
       "0  0.0  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  ...  0.553936  4.656716  0.646438  1.532051  0.210127  2.462585  0.422397  14.074595  7110.0  7100.0\n",
       "1  0.0  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  0.00000  ...  0.553936  4.656716  0.646438  1.532051  0.210127  2.462585  0.422397  14.074595  7110.0  7100.0\n",
       "2  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.497382  0.354839 -0.476190  2.396396  0.411141  1.803571  0.286624  14.044944  7125.0  7115.0\n",
       "3  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.497382  0.354839 -0.476190  1.003774  0.001883  0.909910 -0.047170  14.044944  7125.0  7115.0\n",
       "4  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.926773  0.040590 -0.921986  0.406107 -0.422367  0.268617 -0.576520  14.044944  7125.0  7115.0\n",
       "5  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.926773  0.040590 -0.921986  0.416794 -0.411638  0.275266 -0.568300  14.044944  7125.0  7115.0\n",
       "6  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.926773  0.040590 -0.921986  0.737405 -0.151142  0.474734 -0.356177  14.044944  7125.0  7115.0\n",
       "7  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.922374  0.044280 -0.915194  0.738931 -0.150132  0.477394 -0.353735  14.044944  7125.0  7115.0\n",
       "8  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.922374  0.044280 -0.915194  0.738931 -0.150132  0.477394 -0.353735  14.044944  7125.0  7115.0\n",
       "9  1.0  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  0.21097  ... -0.912188  0.049815 -0.905097  0.741985 -0.148116  0.481383 -0.350090  14.044944  7125.0  7115.0\n",
       "\n",
       "[10 rows x 68 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 0列是要预测的label\n",
    "\n",
    "# 查看上午的feature数据，第一列为0代表not trade，第一列为1代表trade，后面列都是feature value\n",
    "data_2014_up[0].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置需要使用到的ML、DL模型，设置random_state使结果可复制\n",
    "# 可以自行添加更多的分类器，例如MLP，xgboost，软投票分类器等等二分类工具\n",
    "\n",
    "models = {\n",
    "    'RandomForestClassifier': RandomForestClassifier(random_state = 0),\n",
    "    'ExtraTreesClassifier': ExtraTreesClassifier(random_state = 0),\n",
    "    'AdaBoostClassifier': AdaBoostClassifier(base_estimator = DecisionTreeClassifier(), n_estimators = 10,random_state = 0),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(random_state = 0),\n",
    "    'SVC': SVC(probability=True,random_state = 0),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置hyperparameter tuning的网格搜索参数\n",
    "\n",
    "model_grid_params = {\n",
    "    'RandomForestClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                               'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                               'min_samples_leaf':[3]},\n",
    "    'ExtraTreesClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                             'min_samples_split':[2],'criterion':['entropy'],\\\n",
    "                             'min_samples_leaf':[3]},\n",
    "    'AdaBoostClassifier': {\"base_estimator__criterion\" : [\"entropy\"],\\\n",
    "                           \"base_estimator__max_depth\": [None],\\\n",
    "                           \"base_estimator__min_samples_leaf\" : [3],\\\n",
    "                           \"base_estimator__min_samples_split\" : [2],\\\n",
    "                           \"base_estimator__max_features\" : [None]},\n",
    "    'GradientBoostingClassifier': {'max_features':[None],'n_estimators':[10],'max_depth':[10],\\\n",
    "                                   'min_samples_split':[2],'min_samples_leaf':[3],\\\n",
    "                                   'learning_rate':[0.1],'subsample':[1.0]},\n",
    "    'SVC': [{'kernel':['rbf'],'gamma':[1e-1],'C':[1]},\\\n",
    "            {'kernel':['linear'],'C':[1, 10]}]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Model Selection Pipline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model_Selection:\n",
    "    \n",
    "    def __init__(self,models,model_grid_params,data_2014,latest_sec,pred_sec,day):\n",
    "        self.models = models\n",
    "        self.model_grid = model_grid_params\n",
    "        self.data_2014 = data_2014\n",
    "        self.latest_sec = latest_sec\n",
    "        self.pred_sec = pred_sec\n",
    "        self.day = day\n",
    "        self.keys = models.keys()\n",
    "        self.best_score = {}\n",
    "        self.grid = {}\n",
    "        self.predict_values = {}\n",
    "        self.cv_acc = {}\n",
    "        self.acc = {}\n",
    "        self.fscore = {}\n",
    "        self.true_values = {}\n",
    "        self.predict_values_day = {}\n",
    "        self.cv_acc_day = {}\n",
    "        self.acc_day = {}\n",
    "        self.fscore_day = {}\n",
    "        self.true_values_day = {}\n",
    "        self.summary_day = []\n",
    "        \n",
    "    def Grid_fit(self,X_train,y_train,cv = 5,scoring = 'accuracy'):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            model_grid = self.model_grid[key]\n",
    "            Grid = GridSearchCV(model, model_grid, cv = cv, scoring = scoring)\n",
    "            Grid.fit(X_train,y_train) \n",
    "            self.grid[key] = Grid\n",
    "            print(Grid.best_params_)\n",
    "            print('CV Best Score = %s'%(Grid.best_score_))\n",
    "            self.cv_acc[key].append(Grid.best_score_)  \n",
    "    \n",
    "    def model_fit(self,X_train, y_train, X_test, y_test):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            print(\"Running training & testing for %s.\" %(key))\n",
    "            model = self.models[key]\n",
    "            # print(self.grid[key].best_params_)\n",
    "            model.set_params(**self.grid[key].best_params_)\n",
    "            model.fit(X_train, y_train)\n",
    "            predictions = model.predict(X_test)\n",
    "            #print 'Prediction latest 15 second = %s'%(predictions)\n",
    "            self.predict_values[key].append(predictions.tolist())\n",
    "            self.true_values[key].append(y_test.tolist())\n",
    "            acc = metrics.accuracy_score(y_test,predictions)\n",
    "            f_score = metrics.f1_score(y_test,predictions)\n",
    "            print('Accuracy = %s'%(acc))\n",
    "            self.acc[key].append(acc)\n",
    "            self.fscore[key].append(f_score)\n",
    "            \n",
    "            if key == 'SVC':\n",
    "                if self.grid[key].best_params_['kernel'] == 'linear':\n",
    "                    feature_imp = dict(zip([i for i in range(0,64,1)],model.coef_[0]))\n",
    "                    Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                    print('Kernel is linear and top five importance features = %s'%(Top_five))\n",
    "                else:\n",
    "                    print('Kernel is rbf')\n",
    "                    pass\n",
    "            else: \n",
    "                feature_imp = dict(zip([i for i in range(0,64,1)],model.feature_importances_))\n",
    "                Top_five = sorted(feature_imp.items(),key = lambda x : x[1] , reverse=True)[0:5]\n",
    "                print('Top five importance features = %s'%(Top_five))\n",
    "                pass\n",
    "\n",
    "    def pipline(self):\n",
    "        \n",
    "        self.set_list_day() # store day values\n",
    "        for day in range(0,self.day,1):\n",
    "            self.set_list() # store values\n",
    "            print('Day = %s'%(day+1))\n",
    "            for i in range(0, 9000-self.latest_sec-600, self.pred_sec):\n",
    "            # for i in range(0, 9000-self.latest_sec-600, self.pred_sec):\n",
    "            # for i in range(0, 200, self.pred_sec):\n",
    "\n",
    "                \n",
    "                print('--------------------Rolling Window Time = %s--------------------'%(i/pred_sec))\n",
    "                # Train data\n",
    "                data_train = self.data_2014[day][i:i+self.latest_sec]\n",
    "                # X_train = data_train.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                X_train = data_train.drop(['0','65','66','67'],axis=1)\n",
    "                y_train = data_train['0']\n",
    "\n",
    "                # Test data\n",
    "                data_test = self.data_2014[day][i + self.latest_sec:i + self.latest_sec + self.pred_sec]\n",
    "                # X_test = data_test.drop(['0'],axis=1)#,'65','66','67'],axis=1)\n",
    "                X_test = data_test.drop(['0','65','66','67'],axis=1)\n",
    "                y_test = data_test['0']\n",
    "                \n",
    "                #start = time.time()\n",
    "                self.Grid_fit(X_train, y_train, cv = 5, scoring = 'accuracy')\n",
    "                self.model_fit(X_train, y_train,X_test,y_test)\n",
    "                #end = time.time()\n",
    "                #print 'Total Time = %s'%(end - start)\n",
    "                \n",
    "            for key in self.keys:\n",
    "                \n",
    "                self.cv_acc_day[key].append(self.cv_acc[key])\n",
    "                self.acc_day[key].append(self.acc[key])\n",
    "                self.fscore_day[key].append(self.fscore[key])\n",
    "                self.true_values_day[key].append(self.true_values[key])\n",
    "                self.predict_values_day[key].append(self.predict_values[key])\n",
    "            \n",
    "            self.summary_day.append(self.score_summary(sort_by = 'Accuracy_mean'))\n",
    "    \n",
    "    def set_list(self):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            self.predict_values[key] = []\n",
    "            self.cv_acc[key] = []\n",
    "            self.acc[key] = []\n",
    "            self.fscore[key] = []\n",
    "            self.true_values[key] = []\n",
    "            \n",
    "    def set_list_day(self):\n",
    "        \n",
    "        for key in self.keys:\n",
    "            self.predict_values_day[key] = []\n",
    "            self.cv_acc_day[key] = []\n",
    "            self.acc_day[key] = []\n",
    "            self.fscore_day[key] = []\n",
    "            self.true_values_day[key] = []\n",
    "            \n",
    "    def score_summary(self,sort_by):\n",
    "        \n",
    "        summary = pd.concat([pd.DataFrame(self.acc.keys()),pd.DataFrame(map(lambda x: np.mean(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.std(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.max(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.min(self.acc[x]), self.acc)),\\\n",
    "                             pd.DataFrame(map(lambda x: np.mean(self.fscore[x]), self.fscore))],axis=1)\n",
    "        summary.columns = ['Estimator','Accuracy_mean','Accuracy_std','Accuracy_max','Accuracy_min','F_score']\n",
    "        summary.index.rename('Ranking', inplace=True)\n",
    "        return summary.sort_values(by = [sort_by], ascending=False)\n",
    "          \n",
    "    def print_(self):\n",
    "        print(self.predict_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 试运行一组参数\n",
    "# 此处训练集为30min滚动窗口，测试集为未来10s的label值\n",
    "########## 30mins stucking in \n",
    "latest_sec = 60 * 30\n",
    "#latest_sec = 60 * 5\n",
    "######################################\n",
    "pred_sec = 10\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)\n",
    "day = 1\n",
    "data_2014 = data_2014_up\n",
    "# day=2\n",
    "# data_2014 = data_2014_up + data_2014_down\n",
    "pip = Model_Selection(models,model_grid_params,data_2014,latest_sec,pred_sec,day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day = 1\n",
      "--------------------Rolling Window Time = 0.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.8466666666666667\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.97\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.8766666666666666\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.8466666666666667\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 0.9633333333333333\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(30, 0.5836161396759282), (31, 0.24481634696962878), (34, 0.03164188391677345), (46, 0.029473704516661335), (47, 0.021371822669473423)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.3112554676816425), (35, 0.1055367554039686), (33, 0.07357204828338844), (32, 0.06953703141312487), (47, 0.06620242183235266)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(32, 0.4999979561617935), (30, 0.40631284188456435), (35, 0.06849719436842291), (48, 0.02518996374701271), (17, 1.7063903926558006e-06)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.5261110579903939), (30, 0.36047125308866473), (47, 0.043405348167238976), (46, 0.03613182184550887), (34, 0.02196638648163868)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 1.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.8733333333333334\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.8733333333333334\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.8733333333333334\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(30, 0.6080350633401012), (31, 0.26436645540317355), (46, 0.031227452729591026), (34, 0.030014168981474996), (47, 0.028691418647079484)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.36297231924414225), (37, 0.08894494730220212), (35, 0.08562594625430267), (47, 0.07581282928657158), (36, 0.07252415195704984)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(30, 0.8632347274452589), (35, 0.13676527255474116), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.5368569015316714), (30, 0.3611617464869735), (47, 0.043588933482924176), (46, 0.036303014652962665), (34, 0.022089403845464945)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 2.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9033333333333333\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9033333333333333\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9033333333333333\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(30, 0.6256079562784844), (31, 0.2558453516646571), (35, 0.04836185152396695), (47, 0.0303097119003982), (34, 0.02586212176806794)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.34689286144247444), (35, 0.09906164438501333), (37, 0.08814493590818509), (47, 0.08297421062068931), (36, 0.0734907002911583)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(30, 0.8632347274452589), (35, 0.13676527255474116), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.5368569015316714), (30, 0.36116174648697347), (47, 0.04358893348292418), (46, 0.036303014652963435), (34, 0.02208940384546495)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 3.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9600000000000002\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 1.0\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9600000000000002\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9600000000000002\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.48195374141473524), (46, 0.2792630387170184), (30, 0.10503901499165136), (31, 0.08589846579847808), (62, 0.011021014008904305)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.38736226425975373), (35, 0.17578014472437087), (34, 0.09387060944414072), (36, 0.08107546041824548), (47, 0.07252415195704986)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.9279809914139099), (30, 0.07201900858609019), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.5560147631632522), (47, 0.39843867813229095), (33, 0.01409176515662851), (30, 0.00979747129874078), (62, 0.006416055546266623)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 4.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9733333333333333\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9066666666666666\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 1.0\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.6), (46, 0.4), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.2469760159679372), (35, 0.19291913236620734), (34, 0.11481276381494361), (47, 0.10344136974975104), (36, 0.08474973338205097)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.582658947399694), (47, 0.41734105260030174), (33, 1.4539744329405451e-15), (56, 6.155448943759774e-16), (36, 4.922427917255463e-16)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 5.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9733333333333334\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.6), (46, 0.4), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.28070854286573405), (35, 0.17046432442831572), (36, 0.1417042994534434), (50, 0.08831166932840259), (34, 0.07769096266466652)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.5828941065145932), (47, 0.4171058934854034), (53, 1.2171958195826207e-15), (32, 1.1182227700098199e-15), (52, 6.856204206979517e-16)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 6.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9966666666666667\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.6), (46, 0.4), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.2923544101646716), (35, 0.11813971278123274), (50, 0.10108914971176886), (37, 0.08827747474268517), (34, 0.07335328237075604)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.5832746123339626), (47, 0.4167253876660315), (30, 2.091692714795547e-15), (40, 8.329800288134645e-16), (45, 6.419203256722389e-16)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 7.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9533333333333334\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9600000000000002\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9199999999999999\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'kernel': 'linear'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.6), (46, 0.4), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.2610540038058381), (35, 0.10462896698987234), (37, 0.09100006447112549), (50, 0.09020689910793075), (36, 0.06605884958499782)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.5839157830643231), (47, 0.41608421693567177), (62, 2.2877383950354304e-15), (53, 1.601640843684493e-15), (42, 4.623715870619842e-16)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is linear and top five importance features = [(31, 0.5175674840178687), (30, 0.4338350914522372), (34, 0.28679753789920875), (37, 0.2511284645013922), (47, 0.22503321837483292)]\n",
      "--------------------Rolling Window Time = 8.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9233333333333335\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9966666666666667\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.89\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9466666666666667\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.6), (46, 0.4), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.26461158888239156), (35, 0.09290574473201656), (37, 0.08399325507872643), (47, 0.08258806216501782), (36, 0.05715805394087016)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.5846424485482348), (47, 0.4153575514517643), (52, 5.246734469011013e-16), (41, 3.8301762846449003e-16), (61, 9.588531850364265e-17)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 9.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.97\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 1.0\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.97\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.97\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 0.8\n",
      "Top five importance features = [(47, 0.6), (46, 0.4), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 0.3\n",
      "Top five importance features = [(31, 0.23094560952565568), (55, 0.0962229778519675), (47, 0.09535555193060263), (37, 0.08399325507872642), (36, 0.057158053940870146)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 0.8\n",
      "Top five importance features = [(47, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 0.8\n",
      "Top five importance features = [(46, 0.5846424485482347), (47, 0.4153575514517643), (48, 5.421573899899026e-16), (41, 4.0008459454119016e-16), (61, 9.588531850364265e-17)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 0.3\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 10.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9633333333333333\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9933333333333334\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9633333333333333\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9633333333333333\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 0.9766666666666666\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 0.3\n",
      "Top five importance features = [(47, 0.5776242452583462), (46, 0.39008295007728017), (42, 0.007683149629435479), (49, 0.0055176425753989886), (53, 0.00491326350858916)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 0.9\n",
      "Top five importance features = [(31, 0.2258455393810879), (34, 0.14672755379662775), (37, 0.08374407099377451), (47, 0.08307093208629981), (35, 0.06233917871598139)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 0.5\n",
      "Top five importance features = [(46, 0.49999977978429244), (47, 0.4866301616003381), (54, 0.013369838399661833), (40, 1.8777266746882033e-07), (33, 3.2443040089559e-08)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 0.3\n",
      "Top five importance features = [(46, 0.5768125770238243), (47, 0.4101708251908158), (56, 0.003970643591628592), (49, 0.0024423912270435926), (50, 0.0016531766081093332)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 11.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9400000000000001\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9566666666666667\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9400000000000001\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9400000000000001\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 0.9566666666666667\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.4786398456029438), (46, 0.32714622382223685), (62, 0.046303481877122535), (63, 0.040456216947210896), (61, 0.0368775565600631)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.15057633253950578), (31, 0.14056891163905333), (34, 0.13179723903457338), (35, 0.06337912975789177), (61, 0.051937903488538155)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.8115157628353962), (61, 0.18848423716460386), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.47474725145270147), (47, 0.33728282373526725), (63, 0.07131080850150427), (62, 0.046326463129787415), (60, 0.04236647126172421)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 12.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9199999999999999\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9433333333333334\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9199999999999999\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9199999999999999\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 0.9433333333333334\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.4330740069088095), (46, 0.29649441957230527), (62, 0.10957510620519181), (63, 0.052090982684147955), (61, 0.0501989100207043)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(31, 0.18703213738748178), (34, 0.14900198447055646), (35, 0.13724893684436454), (37, 0.07259501210752382), (47, 0.0660986133195584)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.7378405341325801), (61, 0.2621594658674197), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.41892746880100207), (47, 0.297625819180856), (63, 0.10753217154988731), (60, 0.06388594872799673), (34, 0.053553420791186246)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 13.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9133333333333333\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.8966666666666667\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.8366666666666667\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.8833333333333334\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 0.9099999999999999\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.2317684611471333), (46, 0.2280624571177047), (62, 0.17360800726407014), (63, 0.06865998829551849), (48, 0.06839292038601698)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(35, 0.13237393177697357), (15, 0.10001078681870924), (50, 0.08207480214814482), (62, 0.0576651273007105), (16, 0.050842954862722105)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(47, 0.6306142972193253), (61, 0.3693857027806747), (0, 0.0), (1, 0.0), (2, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(51, 0.27897618846619493), (46, 0.14833694972714498), (63, 0.10438674269302571), (62, 0.09606958788923296), (47, 0.055506327267846364)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 14.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.89\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.8400000000000001\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.89\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.8699999999999999\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 0.9066666666666666\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(46, 0.2168873814619488), (47, 0.16500714140719833), (62, 0.14098016659749826), (51, 0.12513819813775579), (63, 0.10080125645778888)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(35, 0.10027118173444557), (37, 0.0981282806253133), (62, 0.08258680775343474), (34, 0.07094400902102702), (50, 0.07038942603528461)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(48, 0.6191506733079207), (63, 0.1946324349419023), (46, 0.18621689175017694), (0, 0.0), (1, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(51, 0.28977792696589116), (46, 0.15598464990622182), (63, 0.10532022676527567), (62, 0.09715576376481241), (47, 0.0751056337678063)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 15.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9233333333333335\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.9233333333333335\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.9233333333333335\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.9833333333333334\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(48, 0.3), (51, 0.3), (46, 0.1), (50, 0.1), (62, 0.1)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(62, 0.13785130104324078), (37, 0.11421147389709527), (50, 0.11285754110437658), (48, 0.08499302673323836), (49, 0.08499302673323836)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(48, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(51, 0.42713291935302916), (46, 0.1646143256674323), (63, 0.14588479465047322), (62, 0.13448633226997475), (50, 0.07058953351474286)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 16.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.89\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 0.89\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 0.89\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n",
      "{'learning_rate': 0.1, 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10, 'subsample': 1.0}\n",
      "CV Best Score = 0.8833333333333334\n",
      "Running GridSearchCV for SVC.\n",
      "{'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "CV Best Score = 1.0\n",
      "Running training & testing for RandomForestClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(51, 0.3), (48, 0.2), (30, 0.1), (46, 0.1), (50, 0.1)]\n",
      "Running training & testing for ExtraTreesClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(63, 0.18978154604233463), (62, 0.11850765093520575), (51, 0.10000000000000002), (19, 0.08149234906479425), (48, 0.07742703223575977)]\n",
      "Running training & testing for AdaBoostClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(48, 1.0), (0, 0.0), (1, 0.0), (2, 0.0), (3, 0.0)]\n",
      "Running training & testing for GradientBoostingClassifier.\n",
      "Accuracy = 1.0\n",
      "Top five importance features = [(51, 0.5425049788589823), (46, 0.1324333624213122), (63, 0.1164711337853001), (62, 0.10566488985036147), (50, 0.05672219884847644)]\n",
      "Running training & testing for SVC.\n",
      "Accuracy = 1.0\n",
      "Kernel is rbf\n",
      "--------------------Rolling Window Time = 17.0--------------------\n",
      "Running GridSearchCV for RandomForestClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 1.0\n",
      "Running GridSearchCV for ExtraTreesClassifier.\n",
      "{'criterion': 'entropy', 'max_depth': 10, 'max_features': None, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 10}\n",
      "CV Best Score = 1.0\n",
      "Running GridSearchCV for AdaBoostClassifier.\n",
      "{'base_estimator__criterion': 'entropy', 'base_estimator__max_depth': None, 'base_estimator__max_features': None, 'base_estimator__min_samples_leaf': 3, 'base_estimator__min_samples_split': 2}\n",
      "CV Best Score = 1.0\n",
      "Running GridSearchCV for GradientBoostingClassifier.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 427, in fit\n    y = self._validate_y(y, sample_weight)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 1210, in _validate_y\n    raise ValueError(\nValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# 模型拟合\u001b[39;00m\n\u001b[1;32m      2\u001b[0m start \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m----> 3\u001b[0m \u001b[43mpip\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpipline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTotal Time = \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39m(end\u001b[38;5;241m-\u001b[39mstart))\n",
      "Cell \u001b[0;32mIn[9], line 95\u001b[0m, in \u001b[0;36mModel_Selection.pipline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     92\u001b[0m y_test \u001b[38;5;241m=\u001b[39m data_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m0\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     94\u001b[0m \u001b[38;5;66;03m#start = time.time()\u001b[39;00m\n\u001b[0;32m---> 95\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mGrid_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_fit(X_train, y_train,X_test,y_test)\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m#end = time.time()\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m#print 'Total Time = %s'%(end - start)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 32\u001b[0m, in \u001b[0;36mModel_Selection.Grid_fit\u001b[0;34m(self, X_train, y_train, cv, scoring)\u001b[0m\n\u001b[1;32m     30\u001b[0m model_grid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_grid[key]\n\u001b[1;32m     31\u001b[0m Grid \u001b[38;5;241m=\u001b[39m GridSearchCV(model, model_grid, cv \u001b[38;5;241m=\u001b[39m cv, scoring \u001b[38;5;241m=\u001b[39m scoring)\n\u001b[0;32m---> 32\u001b[0m \u001b[43mGrid\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgrid[key] \u001b[38;5;241m=\u001b[39m Grid\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(Grid\u001b[38;5;241m.\u001b[39mbest_params_)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1149\u001b[0m     )\n\u001b[1;32m   1150\u001b[0m ):\n\u001b[0;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:898\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    892\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    893\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    894\u001b[0m     )\n\u001b[1;32m    896\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 898\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    901\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    902\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1419\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1417\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1418\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1419\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_search.py:875\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    870\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    871\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[1;32m    873\u001b[0m     )\n\u001b[0;32m--> 875\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:414\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[0;34m(results, error_score)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[1;32m    408\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    409\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    410\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    411\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    412\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    413\u001b[0m     )\n\u001b[0;32m--> 414\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    418\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    423\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    424\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: \nAll the 5 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n5 fits failed with the following error:\nTraceback (most recent call last):\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 732, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/base.py\", line 1151, in wrapper\n    return fit_method(estimator, *args, **kwargs)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 427, in fit\n    y = self._validate_y(y, sample_weight)\n  File \"/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/ensemble/_gb.py\", line 1210, in _validate_y\n    raise ValueError(\nValueError: y contains 1 class after sample_weight trimmed classes with zero weights, while a minimum of 2 classes are required.\n"
     ]
    }
   ],
   "source": [
    "# 模型拟合\n",
    "start = time.time()\n",
    "pip.pipline()\n",
    "end = time.time()\n",
    "print('Total Time = %s'%(end-start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Performance Metrics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip.summary_day[0].reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.summary_day[1]#.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip.summary_day[2]#.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best Bid and Best Ask**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first day\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (14,5))\n",
    "color_ = ['r','b']\n",
    "plt.plot(data_2014[0]['66'],label = 'Best Ask',color = color_[1])\n",
    "plt.plot(data_2014[0]['67'],label = 'Best Bid',color = color_[0])\n",
    "plt.xlim(0, 9000)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Time(s)',size = 15)\n",
    "plt.ylabel('Price',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/best_bid_ask.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Day Accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "color = []\n",
    "for key in pip.keys:\n",
    "    plt.plot(np.array(pip.acc_day[key])[0],'-o',label = key,lw = 1,markersize = 3)\n",
    "    plt.legend(loc=0)\n",
    "plt.ylim(-0.5,1.5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('Accuracy',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/single_day_accuracy.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-Validation Results**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "color_ = ['r','orange','y','g','b']\n",
    "for index,key in enumerate(pip.keys):\n",
    "    plt.plot(np.array(pip.cv_acc_day[key])[0],'-o',label = key,color = color_[index],lw = 1,markersize = 3)\n",
    "#plot(best_cv_score,'-v',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 6)\n",
    "plt.legend(loc = 0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.savefig(\"./images/CV_result.png\", dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Obtain PnL and Best Cross-Validation Result**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute cum_profit and Best_cv_score\n",
    "dict_ = {}\n",
    "dict_['cum_profit'] = []\n",
    "dict_['Best_cv_score'] = []\n",
    "\n",
    "for day in range(0,1,1):\n",
    "    cum_profit_label = []\n",
    "    cum_profit = []\n",
    "    best_cv_score = []\n",
    "    hold_price = []\n",
    "    true_label = []\n",
    "    predict_label = []\n",
    "    # spread = 0.2 * data_2014[day]['65'][1800:][9::10].values\n",
    "    spread = data_2014[day]['65'][1800:][9::10].values\n",
    "    # loss = 0.2*(data_2014[0]['67'][1800:9000-600][9::10].values - data_2014[day]['67'][1800+600:9000][9::10].values)\n",
    "    # loss = data_2014[0]['67'][1800:9000-600][9::10].values - data_2014[day]['67'][1800+600:9000][9::10].values\n",
    "    loss = -data_2014[day]['65'][1800:][9::10].values\n",
    "    # for j in range(0,len(pip.cv_acc_day.values()[0][day]),1):\n",
    "    for j in range(0,len(pip.cv_acc_day['RandomForestClassifier'][day]),1):\n",
    "    \n",
    "        max_al = {}\n",
    "        for i in range(0,len(pip.keys),1):\n",
    "            max_al[list(pip.keys)[i]] = np.array(pip.cv_acc_day[list(pip.keys)[i]])[day][j]\n",
    "        # select best algorithm in cv = 5    \n",
    "        top_cv_acc = sorted(max_al.items(),key = lambda x : x[1], reverse = True)[0:1][0]\n",
    "        best_cv_score.append(top_cv_acc[1])\n",
    "        submission = pip.predict_values_day[top_cv_acc[0]][day][j][-1]\n",
    "        true_value = pip.true_values_day[top_cv_acc[0]][day][j][-1]\n",
    "        true_label.append(true_value)\n",
    "        predict_label.append(submission)\n",
    "        hold_price.append(data_2014[0]['67'][1800:9000][9::10].values[j])\n",
    "\n",
    "        if submission == true_value:\n",
    "            if submission == 1:\n",
    "                cum_profit_label.append(1)\n",
    "                cum_profit.append(spread[j])\n",
    "            elif submission == 0:\n",
    "                cum_profit_label.append(0)\n",
    "                cum_profit.append(0)\n",
    "        elif submission != true_value:\n",
    "            if submission == 1:\n",
    "                cum_profit_label.append(-1)\n",
    "                cum_profit.append(loss[j])\n",
    "            elif submission == 0:\n",
    "                cum_profit_label.append(0)\n",
    "                cum_profit.append(0)\n",
    "                \n",
    "    dict_['cum_profit'].append(cum_profit)\n",
    "    dict_['Best_cv_score'].append(best_cv_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Best CV Score Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = dict_['Best_cv_score']\n",
    "\n",
    "# 取一部分可视化\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(best_cv_score[0][0:250],'-o',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.ylim(0.55,1)\n",
    "plt.savefig(\"./images/best_CV_result.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_cv_score = dict_['Best_cv_score']\n",
    "\n",
    "# 取全部rolling window可视化\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.plot(best_cv_score[0],'-o',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 5)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)\n",
    "plt.savefig(\"./images/best_CV_result_all.png\", dpi=800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PnL Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cum_profit = dict_['cum_profit']\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (14,8))\n",
    "plt.subplot(211)\n",
    "plt.plot(cum_profit[0],'-o',label = 'Profit & Loss (bps)',lw = 1,markersize = 3)\n",
    "plt.ylabel('Tick',size = 15)\n",
    "plt.legend(loc=0)\n",
    "# plt.ylim(-7.5,2.5)\n",
    "plt.subplot(212)\n",
    "plt.plot(np.cumsum(cum_profit[0]),'-o',label = 'Cum Profit (bps)',lw = 1,markersize = 2)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Rolling Window Numbers',size = 15)\n",
    "plt.ylabel('Profit',size = 15)\n",
    "\n",
    "plt.savefig(\"./images/best_CV_result_all.png\", dpi=800)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total profit in bps\n",
    "cum_profit = dict_['cum_profit']\n",
    "prof = [0] + cum_profit[0]\n",
    "pd.DataFrame(np.cumsum(prof))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_label[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold_price[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({\"signal\": predict_label, \"close\": hold_price})\n",
    "result['pre_close'] = result['close'].shift()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 由交易信号产生实际持仓\n",
    "def position_at_close(df):\n",
    "    \"\"\"\n",
    "    根据signal产生实际持仓。考虑涨跌停不能买入卖出的情况。\n",
    "    所有的交易都是发生在产生信号的K线的结束时\n",
    "    :param df:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # ===由signal计算出实际的每天持有仓位\n",
    "    # 在产生signal的k线结束的时候，进行买入\n",
    "    df['signal'].fillna(method='ffill', inplace=True)\n",
    "    df['signal'].fillna(value=0, inplace=True)  # 将初始行数的signal补全为0\n",
    "    df['pos'] = df['signal'].shift()\n",
    "    df['pos'].fillna(value=0, inplace=True)  # 将初始行数的pos补全为0\n",
    "\n",
    "    return df\n",
    "\n",
    "# 计算资金曲线\n",
    "def equity_curve_with_long_at_close(df, c_rate=2.5/10000, t_rate=1.0/1000, slippage=0.01):\n",
    "    \"\"\"\n",
    "    计算股票的资金曲线。只能做多，不能做空。并且只针对满仓操作\n",
    "    每次交易是以当根K线的收盘价为准。\n",
    "    :param df:\n",
    "    :param c_rate: 手续费，commission fees，默认为万分之2.5\n",
    "    :param t_rate: 印花税，tax，默认为千分之1。etf没有\n",
    "    :param slippage: 滑点，股票默认为0.01元，etf为0.001元\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    # ==找出开仓、平仓条件\n",
    "    condition1 = df['pos'] != 0\n",
    "    condition2 = df['pos'] != df['pos'].shift(1)\n",
    "    open_pos_condition = condition1 & condition2\n",
    "\n",
    "    condition1 = df['pos'] != 0\n",
    "    condition2 = df['pos'] != df['pos'].shift(-1)\n",
    "    close_pos_condition = condition1 & condition2\n",
    "\n",
    "\n",
    "    # ===基本参数\n",
    "    initial_cash = 10000  # 初始资金，默认为10000元\n",
    "\n",
    "    # ===在买入的K线\n",
    "    # 在发出信号的当根K线以收盘价买入\n",
    "    df.loc[open_pos_condition, 'stock_num'] = initial_cash * (1 - c_rate) / (df['pre_close'] + slippage)\n",
    "\n",
    "    # 买入股票之后剩余的钱，扣除了手续费\n",
    "    df['cash'] = initial_cash - df['stock_num'] * (df['pre_close'] + slippage) * (1 + c_rate)\n",
    "\n",
    "    # 收盘时的股票净值\n",
    "    df['stock_value'] = df['stock_num'] * df['close']\n",
    "\n",
    "    # ===在买入之后的K线\n",
    "    # 买入之后现金不再发生变动\n",
    "    df['cash'].fillna(method='ffill', inplace=True)\n",
    "    df.loc[df['pos'] == 0, ['cash']] = None\n",
    "\n",
    "    # ===在卖出的K线\n",
    "    # 股票数量变动\n",
    "    df.loc[close_pos_condition, 'stock_num'] = df['stock_value'] / df['close']  # 看2006年初\n",
    "\n",
    "    # 现金变动\n",
    "    df.loc[close_pos_condition, 'cash'] += df.loc[close_pos_condition, 'stock_num'] * (df['close'] - slippage) * (\n",
    "                1 - c_rate - t_rate)\n",
    "    # 股票价值变动\n",
    "    df.loc[close_pos_condition, 'stock_value'] = 0\n",
    "\n",
    "    # ===账户净值\n",
    "    df['net_value'] = df['stock_value'] + df['cash']\n",
    "\n",
    "    # ===计算资金曲线\n",
    "    df['equity_change'] = df['net_value'].pct_change(fill_method=None)\n",
    "    df.loc[open_pos_condition, 'equity_change'] = df.loc[open_pos_condition, 'net_value'] / initial_cash - 1  # 开仓日的收益率\n",
    "    df['equity_change'].fillna(value=0, inplace=True)\n",
    "    df['equity_curve'] = (1 + df['equity_change']).cumprod()\n",
    "    df['equity_curve_base'] = (df['close'] / df['pre_close']).cumprod()\n",
    "\n",
    "    # ===删除无关数据\n",
    "    df.drop(['stock_num', 'cash', 'stock_value', 'net_value'], axis=1, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = position_at_close(result)\n",
    "df = equity_curve_with_long_at_close(result1, 0, 0, 0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 如果需要具体的index，哪里发生了最大回撤，那两行，再加上一些robust处理\n",
    "def max_drawdown(X):\n",
    "    X = np.array(X)\n",
    "    try:\n",
    "        i = np.argmin((X - np.maximum.accumulate(X))/np.maximum.accumulate(X))\n",
    "        j = np.argmax(X[:i])\n",
    "        return i, j, (X[i]-X[j])/X[j]\n",
    "    except:\n",
    "        return 0\n",
    "max_drawdown(df['equity_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算累积收益, exp_rate为业绩报酬率\n",
    "def cum_return(X: pd.Series, exp_rate=0):\n",
    "    X = np.array(X)\n",
    "    t = (X[-1]-X[0])/X[0]\n",
    "    if t > 0:\n",
    "        return t * (1-exp_rate)\n",
    "    else:\n",
    "        return t\n",
    "cum_return(df['equity_curve'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More: Develop the effect of training window period**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_sec = 10\n",
    "data_2014_up, data_2014_down = read_csv(day_trade)\n",
    "day = 1\n",
    "data_2014 = data_2014_up\n",
    "# day=2\n",
    "# data_2014 = data_2014_up+ data_2014_down\n",
    "\n",
    "color_ = ['r','orange','y','g','b']\n",
    "\n",
    "x = []\n",
    "y = {'RandomForestClassifier': [],\n",
    " 'ExtraTreesClassifier': [],\n",
    " 'AdaBoostClassifier': [],\n",
    " 'GradientBoostingClassifier': [],\n",
    " 'SVC': []}\n",
    "\n",
    "for latest_sec in range(10, 660,2):\n",
    "    pip = Model_Selection(models,model_grid_params,data_2014,latest_sec,pred_sec,day)\n",
    "    pip.pipline()\n",
    "    x.append(latest_sec)\n",
    "    for index,key in enumerate(pip.keys):\n",
    "        y[key].append(pip.cv_acc_day[key][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.ylim(0.6, 1)\n",
    "plt.xlim(0, 700)\n",
    "for index,key in enumerate(pip.keys):\n",
    "    plt.plot(x, y[key],'-o',label = key ,color = color_[index], lw = 1, markersize = 2)\n",
    "    # plot(best_cv_score,'-v',label = 'Best cv 5 folds score',color = 'violet',lw = 1,markersize = 6)\n",
    "plt.legend(loc=0)\n",
    "plt.xlabel('Training Sliding Window',size = 15)\n",
    "plt.ylabel('CV Mean Accuracy',size = 15)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ed225720166559e7176d3793db16a2fd8d295f725007103b21ac3099d2a89ee8"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
